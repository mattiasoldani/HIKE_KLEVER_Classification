{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92df3fca",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import LogNorm, LinearSegmentedColormap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fbbcba",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# open data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500a9855",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# data folder(s) (shall have \"/\" at the end):\n",
    "masterpath = \"/DATA_MASTER_PATH/\"\n",
    "datapath = [\n",
    "    masterpath + \"23_hike_pinunu-background/2305_zoptical-zanalyze_training/\",\n",
    "    #masterpath + \"23_hike_pinunu-background/2305_zoptical-zanalyze_2pi_mass_prod/\"\n",
    "]\n",
    "\n",
    "# data selection criteria, set here:\n",
    "def datasel(name):\n",
    "    sel = (\".csv\" in name) & (\"_V2_\" in name) & (not (\"lambda\" in name))\n",
    "    for i in range(500):\n",
    "        if i>100:\n",
    "            sel = sel &  (not (\"_\"+str(i)+\".\" in name))\n",
    "    return sel\n",
    "\n",
    "filenames = []\n",
    "for s in datapath:\n",
    "    filenames += [s+f.name for f in list(os.scandir(s)) if datasel(f.name)]\n",
    "print(\"list of files to open:\")\n",
    "print(*filenames, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e554371",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for name in filenames:\n",
    "    print(\"opening file %s\" % name.rsplit('/', 1)[-1])\n",
    "    df0 = pd.read_csv(name)\n",
    "    df0[\"file\"] = name.replace(\".csv\", \"\")\n",
    "    df = df.append(df0, ignore_index=True, sort=False)\n",
    "    \n",
    "print(\"total events: %d\" % df.shape[0])\n",
    "for i_class in df[\"class\"].unique():\n",
    "    print(\"events in class %d: %d\" % (i_class, df[df[\"class\"]==i_class].shape[0]))\n",
    "print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6706e436",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# there are faulty vertex (as reconstructed by the calorimeter) data --> throwing them away\n",
    "if True:\n",
    "    print(\"removing %d broken-vertex events (%f%%)...\" % (\n",
    "        df[df.Vertex_xRec_Z.isnull()].shape[0], df[df.Vertex_xRec_Z.isnull()].shape[0]/df.shape[0]*100\n",
    "    ))\n",
    "    df = df[~df.Vertex_xRec_Z.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbef50e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "nEvsPop = None  # (max.) nr. of events per class\n",
    "\n",
    "if not (nEvsPop is None):\n",
    "    print(\"after descaling (w/ %d events per class):\" % nEvsPop)\n",
    "\n",
    "    classdf = []\n",
    "    for i, i_class in enumerate(df[\"class\"].unique()):\n",
    "        classdf.append(df[df[\"class\"]==i_class].sample(frac=1).head(nEvsPop))\n",
    "        print(\"events in class %d: %d\" % (i_class, classdf[i].shape[0]))\n",
    "\n",
    "    df = pd.concat(classdf)\n",
    "    print(\"total events: %d\" % df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5056b36e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print(\"list of variables (%d):\" % df.shape[1])\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4ae122",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# condition datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d82863",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# class index\n",
    "\n",
    "# set all possible labels here:\n",
    "classlabel = {\n",
    "    \"k-2pi\" : 0,\n",
    "    \"k-pinunu\" : 1,\n",
    "    \"lambda-pin\" : 5,\n",
    "}\n",
    "\n",
    "for i_class in df[\"class\"].unique():\n",
    "    print(\"class = %d <--> filename type is e.g. %s\" % (i_class, str(df[df[\"class\"] == i_class].file.head(1).values[0]).rsplit('/', 1)[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bce5e3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# variable conditioning\n",
    "\n",
    "# select best vertex quantities\n",
    "df.loc[df.Vertex_nConverted==0, \"Vertex_xBest_Z\"] = df.Vertex_xRec_Z\n",
    "df.loc[df.Vertex_nConverted!=0, \"Vertex_xBest_Z\"] = df.Vertex_xRecPre_Z\n",
    "df.loc[df.Vertex_nConverted==0, \"Vertex_xBest_X\"] = df.Vertex_xRec_X\n",
    "df.loc[df.Vertex_nConverted!=0, \"Vertex_xBest_X\"] = df.Vertex_xRecPre_X\n",
    "df.loc[df.Vertex_nConverted==0, \"Vertex_xBest_Y\"] = df.Vertex_xRec_Y\n",
    "df.loc[df.Vertex_nConverted!=0, \"Vertex_xBest_Y\"] = df.Vertex_xRecPre_Y\n",
    "df.loc[df.Vertex_nConverted==0, \"Vertex_pBest0_Z\"] = df.Vertex_pRec0_Z\n",
    "df.loc[df.Vertex_nConverted!=0, \"Vertex_pBest0_Z\"] = df.Vertex_pRecPre0_Z\n",
    "df.loc[df.Vertex_nConverted==0, \"Vertex_pBest0_X\"] = df.Vertex_pRec0_X\n",
    "df.loc[df.Vertex_nConverted!=0, \"Vertex_pBest0_X\"] = df.Vertex_pRecPre0_X\n",
    "df.loc[df.Vertex_nConverted==0, \"Vertex_pBest0_Y\"] = df.Vertex_pRec0_Y\n",
    "df.loc[df.Vertex_nConverted!=0, \"Vertex_pBest0_Y\"] = df.Vertex_pRecPre0_Y\n",
    "df.loc[df.Vertex_nConverted==0, \"Vertex_pBest1_Z\"] = df.Vertex_pRec1_Z\n",
    "df.loc[df.Vertex_nConverted!=0, \"Vertex_pBest1_Z\"] = df.Vertex_pRecPre1_Z\n",
    "df.loc[df.Vertex_nConverted==0, \"Vertex_pBest1_X\"] = df.Vertex_pRec1_X\n",
    "df.loc[df.Vertex_nConverted!=0, \"Vertex_pBest1_X\"] = df.Vertex_pRecPre1_X\n",
    "df.loc[df.Vertex_nConverted==0, \"Vertex_pBest1_Y\"] = df.Vertex_pRec1_Y\n",
    "df.loc[df.Vertex_nConverted!=0, \"Vertex_pBest1_Y\"] = df.Vertex_pRecPre1_Y\n",
    "\n",
    "# compute all transverse quantities from cartesian components\n",
    "df[\"Vertex_xRec_T\"] = np.sqrt( df.Vertex_xRec_X**2 + df.Vertex_xRec_Y**2 )\n",
    "df[\"Vertex_xRecPre_T\"] = np.sqrt( df.Vertex_xRecPre_X**2 + df.Vertex_xRecPre_Y**2 )\n",
    "df[\"Cluster0_xRec_T\"] = np.sqrt( df.Cluster0_xRec_X**2 + df.Cluster0_xRec_Y**2 )\n",
    "df[\"Cluster1_xRec_T\"] = np.sqrt( df.Cluster1_xRec_X**2 + df.Cluster1_xRec_Y**2 )\n",
    "df[\"Vertex_pRec0_T\"] = np.sqrt( df.Vertex_pRec0_X**2 + df.Vertex_pRec0_Y**2 )\n",
    "df[\"Vertex_pRec1_T\"] = np.sqrt( df.Vertex_pRec1_X**2 + df.Vertex_pRec1_Y**2 )\n",
    "df[\"Cluster0_xPre1_T\"] = np.sqrt( df.Cluster0_xPre1_X**2 + df.Cluster0_xPre1_Y**2 )\n",
    "df[\"Cluster0_xPre2_T\"] = np.sqrt( df.Cluster0_xPre2_X**2 + df.Cluster0_xPre2_Y**2 )\n",
    "df[\"Cluster1_xPre1_T\"] = np.sqrt( df.Cluster1_xPre1_X**2 + df.Cluster1_xPre1_Y**2 )\n",
    "df[\"Cluster1_xPre2_T\"] = np.sqrt( df.Cluster1_xPre2_X**2 + df.Cluster1_xPre2_Y**2 )\n",
    "df[\"Vertex_pRecPre0_T\"] = np.sqrt( df.Vertex_pRecPre0_X**2 + df.Vertex_pRecPre0_Y**2 )\n",
    "df[\"Vertex_pRecPre1_T\"] = np.sqrt( df.Vertex_pRecPre1_X**2 + df.Vertex_pRecPre1_Y**2 )\n",
    "\n",
    "df[\"Vertex_xBest_T\"] = np.sqrt( df.Vertex_xBest_X**2 + df.Vertex_xBest_Y**2 )\n",
    "df[\"Vertex_pBest0_T\"] = np.sqrt( df.Vertex_pBest0_X**2 + df.Vertex_pBest0_Y**2 )\n",
    "df[\"Vertex_pBest1_T\"] = np.sqrt( df.Vertex_pBest1_X**2 + df.Vertex_pBest1_Y**2 )\n",
    "\n",
    "# compute new 2-cluster position and momentum-related variables\n",
    "df[\"Clusters_xRec_TMin\"] = df[[\"Cluster0_xRec_T\", \"Cluster1_xRec_T\"]].min(axis=1)\n",
    "df[\"Clusters_xPre1_TMin\"] = df[[\"Cluster0_xPre1_T\", \"Cluster1_xPre1_T\"]].min(axis=1)\n",
    "df[\"Clusters_xPre2_TMin\"] = df[[\"Cluster0_xPre2_T\", \"Cluster1_xPre2_T\"]].min(axis=1)\n",
    "df[\"Vertex_pRec_TMin\"] = df[[\"Vertex_pRec0_T\", \"Vertex_pRec1_T\"]].min(axis=1)\n",
    "df[\"Vertex_pRecPre_TMin\"] = df[[\"Vertex_pRecPre0_T\", \"Vertex_pRecPre1_T\"]].min(axis=1)\n",
    "df[\"Clusters_xRec_TMax\"] = df[[\"Cluster0_xRec_T\", \"Cluster1_xRec_T\"]].max(axis=1)\n",
    "df[\"Clusters_xPre1_TMax\"] = df[[\"Cluster0_xPre1_T\", \"Cluster1_xPre1_T\"]].max(axis=1)\n",
    "df[\"Clusters_xPre2_TMax\"] = df[[\"Cluster0_xPre2_T\", \"Cluster1_xPre2_T\"]].max(axis=1)\n",
    "df[\"Vertex_pRec_TMax\"] = df[[\"Vertex_pRec0_T\", \"Vertex_pRec1_T\"]].max(axis=1)\n",
    "df[\"Vertex_pRecPre_TMax\"] = df[[\"Vertex_pRecPre0_T\", \"Vertex_pRecPre1_T\"]].max(axis=1)\n",
    "df[\"Clusters_xRec_TSum\"] = df.Clusters_xRec_TMax + df.Clusters_xRec_TMin\n",
    "df[\"Clusters_xPre1_TSum\"] = df.Clusters_xPre1_TMax + df.Clusters_xPre1_TMin\n",
    "df[\"Clusters_xPre2_TSum\"] = df.Clusters_xPre2_TMax + df.Clusters_xPre2_TMin\n",
    "df[\"Vertex_pRec_TSum\"] = df.Vertex_pRec_TMax + df.Vertex_pRec_TMin\n",
    "df[\"Vertex_pRecPre_TSum\"] = df.Vertex_pRecPre_TMax + df.Vertex_pRecPre_TMin\n",
    "df[\"Clusters_xRec_TDif\"] = df.Clusters_xRec_TMax - df.Clusters_xRec_TMin\n",
    "df[\"Clusters_xPre1_TDif\"] = df.Clusters_xPre1_TMax - df.Clusters_xPre1_TMin\n",
    "df[\"Clusters_xPre2_TDif\"] = df.Clusters_xPre2_TMax - df.Clusters_xPre2_TMin\n",
    "df[\"Vertex_pRec_TDif\"] = df.Vertex_pRec_TMax - df.Vertex_pRec_TMin\n",
    "df[\"Vertex_pRecPre_TDif\"] = df.Vertex_pRecPre_TMax - df.Vertex_pRecPre_TMin\n",
    "df[\"Clusters_xRec_TAsym\"] = df.Clusters_xRec_TDif / df.Clusters_xRec_TSum\n",
    "df[\"Clusters_xPre1_TAsym\"] = df.Clusters_xPre1_TDif / df.Clusters_xPre1_TSum\n",
    "df[\"Clusters_xPre2_TAsym\"] = df.Clusters_xPre2_TDif / df.Clusters_xPre2_TSum\n",
    "df[\"Vertex_pRec_TAsym\"] = df.Vertex_pRec_TDif / df.Vertex_pRec_TSum\n",
    "df[\"Vertex_pRecPre_TAsym\"] = df.Vertex_pRecPre_TDif / df.Vertex_pRecPre_TSum\n",
    "\n",
    "df[\"Vertex_pBest_TMin\"] = df[[\"Vertex_pBest0_T\", \"Vertex_pBest1_T\"]].min(axis=1)\n",
    "df[\"Vertex_pBest_TMax\"] = df[[\"Vertex_pBest0_T\", \"Vertex_pBest1_T\"]].max(axis=1)\n",
    "df[\"Vertex_pBest_TSum\"] = df.Vertex_pBest_TMax + df.Vertex_pBest_TMin\n",
    "df[\"Vertex_pBest_TDif\"] = df.Vertex_pBest_TMax - df.Vertex_pBest_TMin\n",
    "df[\"Vertex_pBest_TAsym\"] = df.Vertex_pBest_TDif / df.Vertex_pBest_TSum\n",
    "\n",
    "df[\"Clusters_xDist\"] = np.sqrt(  # distance between clusters\n",
    "    (df.Cluster1_xRec_X-df.Cluster0_xRec_X)**2 + (df.Cluster1_xRec_Y-df.Cluster0_xRec_Y)**2\n",
    ")\n",
    "\n",
    "# compute new 2-cluster energy-related variables\n",
    "df[\"Clusters_EMin\"] = df[[\"Cluster0_ERec\", \"Cluster1_ERec\"]].min(axis=1)\n",
    "df[\"Clusters_EMax\"] = df[[\"Cluster0_ERec\", \"Cluster1_ERec\"]].max(axis=1)\n",
    "df[\"Clusters_ESum\"] = df.Clusters_EMax + df.Clusters_EMin\n",
    "df[\"Clusters_EDif\"] = df.Clusters_EMax - df.Clusters_EMin\n",
    "df[\"Clusters_EAsym\"] = df.Clusters_EDif / df.Clusters_ESum\n",
    "\n",
    "df.loc[df.Cluster0_ERec==df.Clusters_EMin, \"Clusters_xRec_TEMin\"] = df.Cluster0_xRec_T\n",
    "df.loc[df.Cluster0_ERec==df.Clusters_EMin, \"Clusters_xRec_TEMax\"] = df.Cluster1_xRec_T\n",
    "df.loc[df.Cluster1_ERec==df.Clusters_EMin, \"Clusters_xRec_TEMin\"] = df.Cluster1_xRec_T\n",
    "df.loc[df.Cluster1_ERec==df.Clusters_EMin, \"Clusters_xRec_TEMax\"] = df.Cluster0_xRec_T\n",
    "\n",
    "df[\"Clusters_ECOG\"] = np.sqrt(  # centre of gravity between clusters (weighted with energies)\n",
    "    (\n",
    "        (df.Cluster0_ERec*df.Cluster0_xRec_X + df.Cluster1_ERec*df.Cluster1_xRec_X)**2 +\\\n",
    "        (df.Cluster0_ERec*df.Cluster0_xRec_Y + df.Cluster1_ERec*df.Cluster1_xRec_Y)**2\n",
    "    ) / df.Clusters_ESum**2\n",
    ")\n",
    "\n",
    "# compute pion kinematics from two photons (pion energy is simply Clusters_ESum)\n",
    "df[\"Vertex_pRecPi_Z\"] = df.Vertex_pRec0_Z + df.Vertex_pRec1_Z\n",
    "df[\"Vertex_pRecPi_X\"] = df.Vertex_pRec0_X + df.Vertex_pRec1_X\n",
    "df[\"Vertex_pRecPi_Y\"] = df.Vertex_pRec0_Y + df.Vertex_pRec1_Y\n",
    "df[\"Vertex_pRecPrePi_Z\"] = df.Vertex_pRecPre0_Z + df.Vertex_pRecPre1_Z\n",
    "df[\"Vertex_pRecPrePi_X\"] = df.Vertex_pRecPre0_X + df.Vertex_pRecPre1_X\n",
    "df[\"Vertex_pRecPrePi_Y\"] = df.Vertex_pRecPre0_Y + df.Vertex_pRecPre1_Y\n",
    "\n",
    "df[\"Vertex_pRecPi_T\"] = np.sqrt( df.Vertex_pRecPi_X**2 + df.Vertex_pRecPi_Y**2 )\n",
    "df[\"Vertex_pRecPrePi_T\"] = np.sqrt( df.Vertex_pRecPrePi_X**2 + df.Vertex_pRecPrePi_Y**2 )\n",
    "\n",
    "df[\"Vertex_pRecPi_sTh\"] = df.Vertex_pRecPi_T / np.sqrt(  # pion propagation angle wrt. beam\n",
    "    df.Vertex_pRecPi_T**2 + df.Vertex_pRecPi_Z**2\n",
    ")\n",
    "df[\"Vertex_pRecPrePi_sTh\"] = df.Vertex_pRecPrePi_T / np.sqrt(  # pion propagation angle wrt. beam\n",
    "    df.Vertex_pRecPrePi_T**2 + df.Vertex_pRecPrePi_Z**2\n",
    ")\n",
    "\n",
    "df[\"Vertex_pBestPi_Z\"] = df.Vertex_pBest0_Z + df.Vertex_pBest1_Z\n",
    "df[\"Vertex_pBestPi_X\"] = df.Vertex_pBest0_X + df.Vertex_pBest1_X\n",
    "df[\"Vertex_pBestPi_Y\"] = df.Vertex_pBest0_Y + df.Vertex_pBest1_Y\n",
    "\n",
    "df[\"Vertex_pBestPi_T\"] = np.sqrt( df.Vertex_pBestPi_X**2 + df.Vertex_pBestPi_Y**2 )\n",
    "\n",
    "df[\"Vertex_pBestPi_sTh\"] = df.Vertex_pBestPi_T / np.sqrt(  # pion propagation angle wrt. beam\n",
    "    df.Vertex_pBestPi_T**2 + df.Vertex_pBestPi_Z**2\n",
    ")\n",
    "\n",
    "print(\"(preliminary) nr. of classification variables before drop: %d\" % df.shape[1])\n",
    "\n",
    "# drop everything that isn't needed anymore\n",
    "df = df.drop(columns=[\n",
    "    \n",
    "    # raw variables\n",
    "    \"Vertex_xRec_X\", \"Vertex_xRec_Y\",\n",
    "    \"Vertex_xRecPre_X\", \"Vertex_xRecPre_Y\",\n",
    "    \"Cluster0_xRec_X\", \"Cluster0_xRec_Y\",\n",
    "    \"Cluster1_xRec_X\", \"Cluster1_xRec_Y\",\n",
    "    \"Vertex_pRec0_X\", \"Vertex_pRec0_Y\",\n",
    "    \"Vertex_pRec1_X\", \"Vertex_pRec1_Y\",\n",
    "    \"Cluster0_xPre1_X\", \"Cluster0_xPre1_Y\",\n",
    "    \"Cluster0_xPre2_X\", \"Cluster0_xPre2_Y\",\n",
    "    \"Cluster1_xPre1_X\", \"Cluster1_xPre1_Y\",\n",
    "    \"Cluster1_xPre2_X\", \"Cluster1_xPre2_Y\",\n",
    "    \"Vertex_pRecPre0_X\", \"Vertex_pRecPre0_Y\",\n",
    "    \"Vertex_pRecPre1_X\", \"Vertex_pRecPre1_Y\",\n",
    "    \n",
    "    # newly created variables\n",
    "    \"Vertex_xBest_X\", \"Vertex_xBest_Y\",\n",
    "    \"Vertex_pBest0_X\", \"Vertex_pBest0_Y\",\n",
    "    \"Vertex_pBest1_X\", \"Vertex_pBest1_Y\",\n",
    "    \n",
    "    \"Vertex_pRecPi_X\", \"Vertex_pRecPi_Y\",\n",
    "    \"Vertex_pRecPrePi_X\", \"Vertex_pRecPrePi_Y\",\n",
    "])\n",
    "\n",
    "print(\"(preliminary) nr. of classification variables after drop: %d\" % df.shape[1])\n",
    "print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f925195",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# boolean analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e111664",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "bPreBool = True  # perform preliminary boolean analysis, to be compare to the results in the LoI?\n",
    "\n",
    "shift_fv = 150  # FV frame shift to match the data reference system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc2324f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "if bPreBool:\n",
    "\n",
    "    # booleans\n",
    "    bool_sig = df[\"class\"] == classlabel[\"k-pinunu\"]\n",
    "    bool_bkg = ~bool_sig\n",
    "    bool_2mec = df[\"class\"] != -9999\n",
    "    bool_fv = (df.Vertex_xRec_Z > (280-shift_fv)) & (df.Vertex_xRec_Z < (350-shift_fv))\n",
    "    bool_rmin = df.Clusters_xRec_TMin>35e-2\n",
    "    bool_emin = df.Clusters_EMin > (2 / (df.Clusters_xRec_TEMin))\n",
    "    bool_pt = df.Vertex_pRecPi_T > 0.140\n",
    "    bool_psv = (df.Vertex_nConverted > 0) & (df.Vertex_xRecPre_Z < (350-shift_fv)) & (df.Vertex_pRecPrePi_T > 0.140)\n",
    "    bool_even = df.iPair == 1\n",
    "    bool_nofused = (df.Cluster0_nHits == 1) & (df.Cluster1_nHits == 1)\n",
    "\n",
    "    # now count events...\n",
    "\n",
    "    # with 2 photons in MEC (i.e. the total dataset for each class)\n",
    "    n_sig_2mec = df[bool_sig & bool_2mec].shape[0]\n",
    "    n_bkg_2mec = df[bool_bkg & bool_2mec].shape[0]\n",
    "    n_bkgEv_2mec = df[bool_nofused & bool_even & bool_bkg & bool_2mec].shape[0]\n",
    "    n_bkgOd_2mec = df[bool_nofused & ~bool_even & bool_bkg & bool_2mec].shape[0]\n",
    "    n_bkgFs_2mec = df[~bool_nofused & bool_bkg & bool_2mec].shape[0]\n",
    "\n",
    "    # reconstructed in FV with MEC only\n",
    "    n_sig_2mec_fv = df[bool_sig & bool_2mec & bool_fv].shape[0]\n",
    "    n_bkg_2mec_fv = df[bool_bkg & bool_2mec & bool_fv].shape[0]\n",
    "    n_bkgEv_2mec_fv = df[bool_nofused & bool_even & bool_bkg & bool_2mec & bool_fv].shape[0]\n",
    "    n_bkgOd_2mec_fv = df[bool_nofused & ~bool_even & bool_bkg & bool_2mec & bool_fv].shape[0]\n",
    "    n_bkgFs_2mec_fv = df[~bool_nofused & bool_bkg & bool_2mec & bool_fv].shape[0]\n",
    "\n",
    "    # cut on minimum-radius cluster (>35 cm)\n",
    "    n_sig_2mec_fv_rmin = df[bool_sig & bool_2mec & bool_fv & bool_rmin].shape[0]\n",
    "    n_bkg_2mec_fv_rmin = df[bool_bkg & bool_2mec & bool_fv & bool_rmin].shape[0]\n",
    "    n_bkgEv_2mec_fv_rmin = df[bool_nofused & bool_even & bool_bkg & bool_2mec & bool_fv & bool_rmin].shape[0]\n",
    "    n_bkgOd_2mec_fv_rmin = df[bool_nofused & ~bool_even & bool_bkg & bool_2mec & bool_fv & bool_rmin].shape[0]\n",
    "    n_bkgFs_2mec_fv_rmin = df[~bool_nofused & bool_bkg & bool_2mec & bool_fv & bool_rmin].shape[0]\n",
    "\n",
    "    # cut minimum-energy cluster (>2 GeV divided by corresponding cluster radius)\n",
    "    n_sig_2mec_fv_rmin_emin = df[bool_sig & bool_2mec & bool_fv & bool_rmin & bool_emin].shape[0]\n",
    "    n_bkg_2mec_fv_rmin_emin = df[bool_bkg & bool_2mec & bool_fv & bool_rmin & bool_emin].shape[0]\n",
    "    n_bkgEv_2mec_fv_rmin_emin = df[bool_nofused & bool_even & bool_bkg & bool_2mec & bool_fv & bool_rmin & bool_emin].shape[0]\n",
    "    n_bkgOd_2mec_fv_rmin_emin = df[bool_nofused & ~bool_even & bool_bkg & bool_2mec & bool_fv & bool_rmin & bool_emin].shape[0]\n",
    "    n_bkgFs_2mec_fv_rmin_emin = df[~bool_nofused & bool_bkg & bool_2mec & bool_fv & bool_rmin & bool_emin].shape[0]\n",
    "\n",
    "    # cut on pion transverse momentum (>0.140 GeV) computed with MEC only\n",
    "    n_sig_2mec_fv_rmin_emin_pt = df[bool_sig & bool_2mec & bool_fv & bool_rmin & bool_emin & bool_pt].shape[0]\n",
    "    n_bkg_2mec_fv_rmin_emin_pt = df[bool_bkg & bool_2mec & bool_fv & bool_rmin & bool_emin & bool_pt].shape[0]\n",
    "    n_bkgEv_2mec_fv_rmin_emin_pt = df[bool_nofused & bool_even & bool_bkg & bool_2mec & bool_fv & bool_rmin & bool_emin & bool_pt].shape[0]\n",
    "    n_bkgOd_2mec_fv_rmin_emin_pt = df[bool_nofused & ~bool_even & bool_bkg & bool_2mec & bool_fv & bool_rmin & bool_emin & bool_pt].shape[0]\n",
    "    n_bkgFs_2mec_fv_rmin_emin_pt = df[~bool_nofused & bool_bkg & bool_2mec & bool_fv & bool_rmin & bool_emin & bool_pt].shape[0]\n",
    "    \n",
    "    # adding the PSV data\n",
    "    n_sig_2mec_fv_rmin_emin_pt_psv = df[bool_sig & bool_2mec & bool_fv & bool_rmin & bool_emin & bool_pt & bool_psv].shape[0]\n",
    "    n_bkg_2mec_fv_rmin_emin_pt_psv = df[bool_bkg & bool_2mec & bool_fv & bool_rmin & bool_emin & bool_pt & bool_psv].shape[0] \n",
    "    n_bkgEv_2mec_fv_rmin_emin_pt_psv = df[bool_nofused & bool_even & bool_bkg & bool_2mec & bool_fv & bool_rmin & bool_emin & bool_pt & bool_psv].shape[0] \n",
    "    n_bkgOd_2mec_fv_rmin_emin_pt_psv = df[bool_nofused & ~bool_even & bool_bkg & bool_2mec & bool_fv & bool_rmin & bool_emin & bool_pt & bool_psv].shape[0] \n",
    "    n_bkgFs_2mec_fv_rmin_emin_pt_psv = df[~bool_nofused & bool_bkg & bool_2mec & bool_fv & bool_rmin & bool_emin & bool_pt & bool_psv].shape[0]     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088d1715",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "if bPreBool:\n",
    "    \n",
    "    # total events (with 2 photons in MEC) in the LoI:\n",
    "    normSig = 302\n",
    "    normBkg = 9.45e7\n",
    "\n",
    "    print(\"counts for signal:\")\n",
    "    print(normSig*n_sig_2mec/n_sig_2mec)\n",
    "    print(normSig*n_sig_2mec_fv/n_sig_2mec)\n",
    "    print(normSig*n_sig_2mec_fv_rmin/n_sig_2mec)\n",
    "    print(normSig*n_sig_2mec_fv_rmin_emin/n_sig_2mec)\n",
    "    print(normSig*n_sig_2mec_fv_rmin_emin_pt/n_sig_2mec)\n",
    "    print(normSig*n_sig_2mec_fv_rmin_emin_pt_psv/n_bkg_2mec)\n",
    "\n",
    "    print(\"---\\ncounts for background (total):\")\n",
    "    print(normBkg*n_bkg_2mec/n_bkg_2mec)\n",
    "    print(normBkg*n_bkg_2mec_fv/n_bkg_2mec)\n",
    "    print(normBkg*n_bkg_2mec_fv_rmin_emin/n_bkg_2mec)\n",
    "    print(normBkg*n_bkg_2mec_fv_rmin_emin_pt/n_bkg_2mec)\n",
    "    print(normBkg*n_bkg_2mec_fv_rmin_emin_pt_psv/n_bkg_2mec)\n",
    "    \n",
    "    print(\"---\\ncounts for background (even, not fused):\")\n",
    "    print(normBkg*n_bkgEv_2mec/n_bkg_2mec)\n",
    "    print(normBkg*n_bkgEv_2mec_fv/n_bkg_2mec)\n",
    "    print(normBkg*n_bkgEv_2mec_fv_rmin_emin/n_bkg_2mec)\n",
    "    print(normBkg*n_bkgEv_2mec_fv_rmin_emin_pt/n_bkg_2mec)\n",
    "    print(normBkg*n_bkgEv_2mec_fv_rmin_emin_pt_psv/n_bkg_2mec)\n",
    "    \n",
    "    print(\"---\\ncounts for background (odd, not fused):\")\n",
    "    print(normBkg*n_bkgOd_2mec/n_bkg_2mec)\n",
    "    print(normBkg*n_bkgOd_2mec_fv/n_bkg_2mec)\n",
    "    print(normBkg*n_bkgOd_2mec_fv_rmin_emin/n_bkg_2mec)\n",
    "    print(normBkg*n_bkgOd_2mec_fv_rmin_emin_pt/n_bkg_2mec)\n",
    "    print(normBkg*n_bkgOd_2mec_fv_rmin_emin_pt_psv/n_bkg_2mec)\n",
    "    \n",
    "    print(\"---\\ncounts for background (fused):\")\n",
    "    print(normBkg*n_bkgFs_2mec/n_bkg_2mec)\n",
    "    print(normBkg*n_bkgFs_2mec_fv/n_bkg_2mec)\n",
    "    print(normBkg*n_bkgFs_2mec_fv_rmin_emin/n_bkg_2mec)\n",
    "    print(normBkg*n_bkgFs_2mec_fv_rmin_emin_pt/n_bkg_2mec)\n",
    "    print(normBkg*n_bkgFs_2mec_fv_rmin_emin_pt_psv/n_bkg_2mec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73317db",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "if bPreBool:\n",
    "    \n",
    "    bPreBool_save = True  # save plots?\n",
    "    \n",
    "    bLog = True\n",
    "    cmap_name = \"jet\"\n",
    "    range_plot = ((150-shift_fv, 400-shift_fv), (0, 0.4)) \n",
    "    \n",
    "    #cmap = LinearSegmentedColormap.from_list(\n",
    "    #    \"%s_white\" % cmap_name, \n",
    "    #    list(np.concatenate((np.array([[0, 0, 0, 0]]), plt.get_cmap(cmap_name)(np.arange(256))))),\n",
    "    #)\n",
    "    cmap = plt.get_cmap(cmap_name).copy()\n",
    "    cmap.set_bad('white')\n",
    "    \n",
    "    for i_class in (0, 1, 2, 3):\n",
    "        fig, ax = plt.subplots(num=i_class, nrows=1, ncols=2, figsize=(12, 4))\n",
    "        \n",
    "        bool_plot = bool_2mec & bool_rmin & bool_emin\n",
    "        if i_class==0:\n",
    "            bool_class = bool_sig\n",
    "            bool_plot = bool_plot & bool_psv\n",
    "        elif i_class==1:\n",
    "            bool_class = bool_bkg & bool_nofused & bool_even \n",
    "            bool_plot = bool_plot & bool_nofused & bool_even \n",
    "        elif i_class==2:\n",
    "            bool_class = bool_bkg & bool_nofused & ~bool_even \n",
    "            bool_plot = bool_plot & bool_nofused & ~bool_even \n",
    "        else:\n",
    "            bool_class = bool_bkg & ~bool_nofused\n",
    "            bool_plot = bool_plot & ~bool_nofused\n",
    "            \n",
    "        ax[0].hist2d(\n",
    "            df[bool_class].Vertex_xRec_Z, df[bool_class].Vertex_pRecPi_T,\n",
    "            bins=(200, 100), range=range_plot, cmap=cmap, norm=LogNorm() if bLog else None, cmin=1\n",
    "        )\n",
    "        ax[1].hist2d(\n",
    "            df[bool_class & bool_plot].Vertex_xRec_Z, df[bool_class & bool_plot].Vertex_pRecPi_T,\n",
    "            bins=(200, 100), range=range_plot, cmap=cmap, norm=LogNorm() if bLog else None, cmin=1\n",
    "        )\n",
    "        \n",
    "        box = ((280-shift_fv, 1), (280-shift_fv, 0.14), (350-shift_fv, 0.14), (350-shift_fv, 1))\n",
    "        x_box, y_box = zip(*box)\n",
    "        ax[0].plot(x_box, y_box, color=\"0.7\", lw=3)\n",
    "        ax[1].plot(x_box, y_box, color=\"0.7\", lw=3)\n",
    "        \n",
    "        titles = [\"signal\", \"background, even, not fused\", \"background, odd, not fused\", \"background, fused\"]\n",
    "        fig.suptitle(titles[i_class])\n",
    "        fig.supxlabel(\"Vertex_xRec_Z [m]\")\n",
    "        fig.supylabel(\"Vertex_pRecPi_T [GeV]\")\n",
    "        fig.tight_layout()\n",
    "        if bPreBool_save:\n",
    "            fig.savefig(\"./output_misc/%s.png\" % titles[i_class].replace(\",\", \"_\").replace(\" \", \"\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

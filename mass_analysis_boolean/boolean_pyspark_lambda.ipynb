{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ed03ea",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, udf, hypot, least, greatest, sum\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm, LinearSegmentedColormap\n",
    "\n",
    "from sparkhistogram import computeWeightedHistogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4132afa",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# start Spark session\n",
    "\n",
    "bLocal = False  # enable only if running locally\n",
    "\n",
    "if bLocal:\n",
    "    spark = (\n",
    "        SparkSession.builder\n",
    "        .master(\"local[*]\")\n",
    "        .appName(\"hike_sensitivity_boolean_pyspark_lambda\")\n",
    "        .config(\"spark.ui.showConsoleProgress\", \"false\")\n",
    "        .getOrCreate()\n",
    "    )\n",
    "    \n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fbbcba",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# open data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f099bbd",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# data folder(s) (shall have \"/\" at the end):\n",
    "masterpath = (\"\" if bLocal else \"root://eosuser.cern.ch/\")+\"/DATA_MASTER_PATH/\"\n",
    "datasets = [\n",
    "    masterpath + \"23_hike_pinunu-background/2306_zoptical-zanalyze_lambda_mass_prod/\",  # whole folder with the mass-production background data\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beea811b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# dataset schema\n",
    "schema =\\\n",
    "\"class string,\" +\\\n",
    "\"iEv int,\" +\\\n",
    "\"W float,\" +\\\n",
    "\"iPair int,\" +\\\n",
    "\"Vertex_nConverted float,\" +\\\n",
    "\"Vertex_xRec_Z float,\" +\\\n",
    "\"Vertex_xRec_X float,\" +\\\n",
    "\"Vertex_xRec_Y float,\" +\\\n",
    "\"Vertex_xRecPre_Z float,\" +\\\n",
    "\"Vertex_xRecPre_X float,\" +\\\n",
    "\"Vertex_xRecPre_Y float,\" +\\\n",
    "\"Cluster0_nHits int,\" +\\\n",
    "\"Cluster0_xRec_Z float,\" +\\\n",
    "\"Cluster0_xRec_X float,\" +\\\n",
    "\"Cluster0_xRec_Y float,\" +\\\n",
    "\"Vertex_pRec0_Z float,\" +\\\n",
    "\"Vertex_pRec0_X float,\" +\\\n",
    "\"Vertex_pRec0_Y float,\" +\\\n",
    "\"Cluster0_ERec float,\" +\\\n",
    "\"Cluster0_PosRes float,\" +\\\n",
    "\"Cluster0_ERes float,\" +\\\n",
    "\"Cluster0_xPre1_Z float,\" +\\\n",
    "\"Cluster0_xPre1_X float,\" +\\\n",
    "\"Cluster0_xPre1_Y float,\" +\\\n",
    "\"Cluster0_xPre2_Z float,\" +\\\n",
    "\"Cluster0_xPre2_X float,\" +\\\n",
    "\"Cluster0_xPre2_Y float,\" +\\\n",
    "\"Vertex_pRecPre0_Z float,\" +\\\n",
    "\"Vertex_pRecPre0_X float,\" +\\\n",
    "\"Vertex_pRecPre0_Y float,\" +\\\n",
    "\"Cluster0_PreRes float,\" +\\\n",
    "\"Cluster1_nHits int,\" +\\\n",
    "\"Cluster1_xRec_Z float,\" +\\\n",
    "\"Cluster1_xRec_X float,\" +\\\n",
    "\"Cluster1_xRec_Y float,\" +\\\n",
    "\"Vertex_pRec1_Z float,\" +\\\n",
    "\"Vertex_pRec1_X float,\" +\\\n",
    "\"Vertex_pRec1_Y float,\" +\\\n",
    "\"Cluster1_ERec float,\" +\\\n",
    "\"Cluster1_PosRes float,\" +\\\n",
    "\"Cluster1_ERes float,\" +\\\n",
    "\"Cluster1_xPre1_Z float,\" +\\\n",
    "\"Cluster1_xPre1_X float,\" +\\\n",
    "\"Cluster1_xPre1_Y float,\" +\\\n",
    "\"Cluster1_xPre2_Z float,\" +\\\n",
    "\"Cluster1_xPre2_X float,\" +\\\n",
    "\"Cluster1_xPre2_Y float,\" +\\\n",
    "\"Vertex_pRecPre1_Z float,\" +\\\n",
    "\"Vertex_pRecPre1_X float,\" +\\\n",
    "\"Vertex_pRecPre1_Y float,\" +\\\n",
    "\"Cluster1_PreRes float\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c8d627",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# open dataset\n",
    "df = (\n",
    "    spark\n",
    "    .read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .csv(datasets, schema=schema)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e07e0a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# there are faulty vertex (as reconstructed by the calorimeter) data --> throwing them away\n",
    "\n",
    "df.select(col(\"Vertex_xRec_Z\").isNotNull().alias(\"Vertex_Rec_Broken\")).groupBy(\"Vertex_Rec_Broken\").count().show()\n",
    "\n",
    "print(\"--> removing all these broken events ('false' above)...\")\n",
    "df = df.filter(col(\"Vertex_xRec_Z\").isNotNull())\n",
    "\n",
    "print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4ae122",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# condition datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b43b152",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# format class variable\n",
    "\n",
    "# set all possible labels here:\n",
    "classlabel = {\n",
    "    \"k-2pi\" : 0,\n",
    "    \"k-pinunu\" : 1,\n",
    "    \"lambda-pin\" : 5,\n",
    "}\n",
    "classlabel_udf = udf(lambda s : {str(s_val) : s_key for s_key, s_val in classlabel.items()}[s])\n",
    "\n",
    "df = df.withColumn(\"class_lab\", classlabel_udf(col(\"class\")))\n",
    "\n",
    "df.groupBy(\"class\", \"class_lab\").count().show()\n",
    "print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbea2163",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# variable conditioning - select best vertex quantities\n",
    "\n",
    "bestvtx_udf = udf(lambda x_rec, x_pre, b_pre : x_pre if b_pre else x_rec )\n",
    "\n",
    "df = df.withColumn(\"Vertex_xBest_Z\", bestvtx_udf(col(\"Vertex_xRec_Z\"), col(\"Vertex_xRecPre_Z\"), col(\"Vertex_nConverted\")).cast(\"double\"))\n",
    "df = df.withColumn(\"Vertex_xBest_X\", bestvtx_udf(col(\"Vertex_xRec_X\"), col(\"Vertex_xRecPre_X\"), col(\"Vertex_nConverted\")).cast(\"double\"))\n",
    "df = df.withColumn(\"Vertex_xBest_Y\", bestvtx_udf(col(\"Vertex_xRec_Y\"), col(\"Vertex_xRecPre_Y\"), col(\"Vertex_nConverted\")).cast(\"double\"))\n",
    "df = df.withColumn(\"Vertex_pBest0_Z\", bestvtx_udf(col(\"Vertex_pRec0_Z\"), col(\"Vertex_pRecPre0_Z\"), col(\"Vertex_nConverted\")).cast(\"double\"))\n",
    "df = df.withColumn(\"Vertex_pBest0_X\", bestvtx_udf(col(\"Vertex_pRec0_X\"), col(\"Vertex_pRecPre0_X\"), col(\"Vertex_nConverted\")).cast(\"double\"))\n",
    "df = df.withColumn(\"Vertex_pBest0_Y\", bestvtx_udf(col(\"Vertex_pRec0_Y\"), col(\"Vertex_pRecPre0_Y\"), col(\"Vertex_nConverted\")).cast(\"double\"))\n",
    "df = df.withColumn(\"Vertex_pBest1_Z\", bestvtx_udf(col(\"Vertex_pRec1_Z\"), col(\"Vertex_pRecPre1_Z\"), col(\"Vertex_nConverted\")).cast(\"double\"))\n",
    "df = df.withColumn(\"Vertex_pBest1_X\", bestvtx_udf(col(\"Vertex_pRec1_X\"), col(\"Vertex_pRecPre1_X\"), col(\"Vertex_nConverted\")).cast(\"double\"))\n",
    "df = df.withColumn(\"Vertex_pBest1_Y\", bestvtx_udf(col(\"Vertex_pRec1_Y\"), col(\"Vertex_pRecPre1_Y\"), col(\"Vertex_nConverted\")).cast(\"double\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecd4337",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# variable conditioning - compute all transverse quantities from cartesian components\n",
    "\n",
    "df = df.withColumn(\"Vertex_xRec_T\", hypot(col(\"Vertex_xRec_X\"), col(\"Vertex_xRec_Y\")).cast(\"double\"))\n",
    "df = df.withColumn(\"Vertex_xRecPre_T\", hypot(col(\"Vertex_xRecPre_X\"), col(\"Vertex_xRecPre_Y\")).cast(\"double\"))\n",
    "df = df.withColumn(\"Cluster0_xRec_T\", hypot(col(\"Cluster0_xRec_X\"), col(\"Cluster0_xRec_Y\")).cast(\"double\"))\n",
    "df = df.withColumn(\"Cluster1_xRec_T\", hypot(col(\"Cluster1_xRec_X\"), col(\"Cluster1_xRec_Y\")).cast(\"double\"))\n",
    "df = df.withColumn(\"Vertex_pRec0_T\", hypot(col(\"Vertex_pRec0_X\"), col(\"Vertex_pRec0_Y\")).cast(\"double\"))\n",
    "df = df.withColumn(\"Vertex_pRec1_T\", hypot(col(\"Vertex_pRec1_X\"), col(\"Vertex_pRec1_Y\")).cast(\"double\"))\n",
    "df = df.withColumn(\"Cluster0_xPre1_T\", hypot(col(\"Cluster0_xPre1_X\"), col(\"Cluster0_xPre1_Y\")).cast(\"double\"))\n",
    "df = df.withColumn(\"Cluster0_xPre2_T\", hypot(col(\"Cluster0_xPre2_X\"), col(\"Cluster0_xPre2_Y\")).cast(\"double\"))\n",
    "df = df.withColumn(\"Cluster1_xPre1_T\", hypot(col(\"Cluster1_xPre1_X\"), col(\"Cluster1_xPre1_Y\")).cast(\"double\"))\n",
    "df = df.withColumn(\"Cluster1_xPre2_T\", hypot(col(\"Cluster1_xPre2_X\"), col(\"Cluster1_xPre2_Y\")).cast(\"double\"))\n",
    "df = df.withColumn(\"Vertex_pRecPre0_T\", hypot(col(\"Vertex_pRecPre0_X\"), col(\"Vertex_pRecPre0_Y\")).cast(\"double\"))\n",
    "df = df.withColumn(\"Vertex_pRecPre1_T\", hypot(col(\"Vertex_pRecPre1_X\"), col(\"Vertex_pRecPre1_Y\")).cast(\"double\"))\n",
    "\n",
    "df = df.withColumn(\"Vertex_xBest_T\", hypot(col(\"Vertex_xBest_X\"), col(\"Vertex_xBest_Y\")).cast(\"double\"))\n",
    "df = df.withColumn(\"Vertex_pBest0_T\", hypot(col(\"Vertex_pBest0_X\"), col(\"Vertex_pBest0_Y\")).cast(\"double\"))\n",
    "df = df.withColumn(\"Vertex_pBest1_T\", hypot(col(\"Vertex_pBest1_X\"), col(\"Vertex_pBest1_Y\")).cast(\"double\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec33f89",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# variable conditioning - compute new 2-cluster position and momentum-related variables\n",
    "\n",
    "xminene_udf = udf(lambda x0, x1, e0, e1 : x0 if (e0<e1) else x1)\n",
    "xmaxene_udf = udf(lambda x0, x1, e0, e1 : x1 if (e0<e1) else x0)\n",
    "\n",
    "df = df.withColumn(\"Clusters_xRec_TMin\", least(col(\"Cluster0_xRec_T\"), col(\"Cluster1_xRec_T\")).cast(\"double\"))\n",
    "df = df.withColumn(\"Clusters_xPre1_TMin\", least(col(\"Cluster0_xPre1_T\"), col(\"Cluster1_xPre1_T\")).cast(\"double\"))\n",
    "df = df.withColumn(\"Clusters_xPre2_TMin\", least(col(\"Cluster0_xPre2_T\"), col(\"Cluster1_xPre2_T\")).cast(\"double\"))\n",
    "df = df.withColumn(\"Vertex_pRec_TMin\", least(col(\"Vertex_pRec0_T\"), col(\"Vertex_pRec1_T\")).cast(\"double\"))\n",
    "df = df.withColumn(\"Vertex_pRecPre_TMin\", least(col(\"Vertex_pRecPre0_T\"), col(\"Vertex_pRecPre1_T\")).cast(\"double\"))\n",
    "df = df.withColumn(\"Clusters_xRec_TMax\", greatest(col(\"Cluster0_xRec_T\"), col(\"Cluster1_xRec_T\")).cast(\"double\"))\n",
    "df = df.withColumn(\"Clusters_xPre1_TMax\", greatest(col(\"Cluster0_xPre1_T\"), col(\"Cluster1_xPre1_T\")).cast(\"double\"))\n",
    "df = df.withColumn(\"Clusters_xPre2_TMax\", greatest(col(\"Cluster0_xPre2_T\"), col(\"Cluster1_xPre2_T\")).cast(\"double\"))\n",
    "df = df.withColumn(\"Vertex_pRec_TMax\", greatest(col(\"Vertex_pRec0_T\"), col(\"Vertex_pRec1_T\")).cast(\"double\"))\n",
    "df = df.withColumn(\"Vertex_pRecPre_TMax\", greatest(col(\"Vertex_pRecPre0_T\"), col(\"Vertex_pRecPre1_T\")).cast(\"double\"))\n",
    "df = df.withColumn(\"Clusters_xRec_TSum\", col(\"Clusters_xRec_TMax\") + col(\"Clusters_xRec_TMin\"))\n",
    "df = df.withColumn(\"Clusters_xPre1_TSum\", col(\"Clusters_xPre1_TMax\") + col(\"Clusters_xPre1_TMin\"))\n",
    "df = df.withColumn(\"Clusters_xPre2_TSum\", col(\"Clusters_xPre2_TMax\") + col(\"Clusters_xPre2_TMin\"))\n",
    "df = df.withColumn(\"Vertex_pRec_TSum\", col(\"Vertex_pRec_TMax\") + col(\"Vertex_pRec_TMin\"))\n",
    "df = df.withColumn(\"Vertex_pRecPre_TSum\", col(\"Vertex_pRecPre_TMax\") + col(\"Vertex_pRecPre_TMin\"))\n",
    "df = df.withColumn(\"Clusters_xRec_TDif\", col(\"Clusters_xRec_TMax\") - col(\"Clusters_xRec_TMin\"))\n",
    "df = df.withColumn(\"Clusters_xPre1_TDif\", col(\"Clusters_xPre1_TMax\") - col(\"Clusters_xPre1_TMin\"))\n",
    "df = df.withColumn(\"Clusters_xPre2_TDif\", col(\"Clusters_xPre2_TMax\") - col(\"Clusters_xPre2_TMin\"))\n",
    "df = df.withColumn(\"Vertex_pRec_TDif\", col(\"Vertex_pRec_TMax\") - col(\"Vertex_pRec_TMin\"))\n",
    "df = df.withColumn(\"Vertex_pRecPre_TDif\", col(\"Vertex_pRecPre_TMax\") - col(\"Vertex_pRecPre_TMin\"))\n",
    "df = df.withColumn(\"Clusters_xRec_TAsym\", col(\"Clusters_xRec_TDif\") / col(\"Clusters_xRec_TSum\"))\n",
    "df = df.withColumn(\"Clusters_xPre1_TAsym\", col(\"Clusters_xPre1_TDif\") / col(\"Clusters_xPre1_TSum\"))\n",
    "df = df.withColumn(\"Clusters_xPre2_TAsym\", col(\"Clusters_xPre2_TDif\") / col(\"Clusters_xPre2_TSum\"))\n",
    "df = df.withColumn(\"Vertex_pRec_TAsym\", col(\"Vertex_pRec_TDif\") / col(\"Vertex_pRec_TSum\"))\n",
    "df = df.withColumn(\"Vertex_pRecPre_TAsym\", col(\"Vertex_pRecPre_TDif\") / col(\"Vertex_pRecPre_TSum\"))\n",
    "\n",
    "df = df.withColumn(\"Vertex_pBest_TMin\", least(col(\"Vertex_pBest0_T\"), col(\"Vertex_pBest1_T\")).cast(\"double\"))\n",
    "df = df.withColumn(\"Vertex_pBest_TMax\", greatest(col(\"Vertex_pBest0_T\"), col(\"Vertex_pBest1_T\")).cast(\"double\"))\n",
    "df = df.withColumn(\"Vertex_pBest_TSum\", col(\"Vertex_pBest_TMax\") + col(\"Vertex_pBest_TMin\"))\n",
    "df = df.withColumn(\"Vertex_pBest_TDif\", col(\"Vertex_pBest_TMax\") - col(\"Vertex_pBest_TMin\"))\n",
    "df = df.withColumn(\"Vertex_pBest_TAsym\", col(\"Vertex_pBest_TDif\") / col(\"Vertex_pBest_TSum\"))\n",
    "\n",
    "df = df.withColumn(\n",
    "    \"Clusters_xDist\",\n",
    "    hypot(col(\"Cluster1_xRec_X\")-col(\"Cluster0_xRec_X\"), col(\"Cluster1_xRec_Y\")-col(\"Cluster0_xRec_Y\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8c6f1a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# variable conditioning - compute new 2-cluster energy-related variables\n",
    "\n",
    "df = df.withColumn(\"Clusters_EMin\", least(col(\"Cluster0_ERec\"), col(\"Cluster1_ERec\")).cast(\"double\"))\n",
    "df = df.withColumn(\"Clusters_EMax\", greatest(col(\"Cluster0_ERec\"), col(\"Cluster1_ERec\")).cast(\"double\"))\n",
    "df = df.withColumn(\"Clusters_ESum\", col(\"Clusters_EMax\") + col(\"Clusters_EMin\"))\n",
    "df = df.withColumn(\"Clusters_EDif\", col(\"Clusters_EMax\") - col(\"Clusters_EMin\"))\n",
    "df = df.withColumn(\"Clusters_EAsym\", col(\"Clusters_EDif\") / col(\"Clusters_ESum\"))\n",
    "\n",
    "df = df.withColumn(\"Clusters_xRec_TEMin\", xminene_udf(col(\"Cluster0_xRec_T\"), col(\"Cluster1_xRec_T\"), col(\"Cluster0_ERec\"), col(\"Cluster1_ERec\")).cast(\"double\"))\n",
    "df = df.withColumn(\"Clusters_xRec_TEMax\", xmaxene_udf(col(\"Cluster0_xRec_T\"), col(\"Cluster1_xRec_T\"), col(\"Cluster0_ERec\"), col(\"Cluster1_ERec\")).cast(\"double\"))\n",
    "\n",
    "df = df.withColumn(\n",
    "    \"Clusters_ECOG\",\n",
    "    hypot(\n",
    "        col(\"Cluster0_ERec\")*col(\"Cluster0_xRec_X\")+col(\"Cluster1_ERec\")*col(\"Cluster1_xRec_X\"),\n",
    "        col(\"Cluster0_ERec\")*col(\"Cluster0_xRec_Y\")+col(\"Cluster1_ERec\")*col(\"Cluster1_xRec_Y\")\n",
    "    ).cast(\"double\") / col(\"Clusters_ESum\").cast(\"double\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d6b696",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# variable conditioning - compute pion kinematics from two photons (pion energy is simply Clusters_ESum)\n",
    "\n",
    "df = df.withColumn(\"Vertex_pRecPi_Z\", col(\"Vertex_pRec0_Z\") + col(\"Vertex_pRec1_Z\"))\n",
    "df = df.withColumn(\"Vertex_pRecPi_X\", col(\"Vertex_pRec0_X\") + col(\"Vertex_pRec1_X\"))\n",
    "df = df.withColumn(\"Vertex_pRecPi_Y\", col(\"Vertex_pRec0_Y\") + col(\"Vertex_pRec1_Y\"))\n",
    "df = df.withColumn(\"Vertex_pRecPrePi_Z\", col(\"Vertex_pRecPre0_Z\") + col(\"Vertex_pRecPre1_Z\"))\n",
    "df = df.withColumn(\"Vertex_pRecPrePi_X\", col(\"Vertex_pRecPre0_X\") + col(\"Vertex_pRecPre1_X\"))\n",
    "df = df.withColumn(\"Vertex_pRecPrePi_Y\", col(\"Vertex_pRecPre0_Y\") + col(\"Vertex_pRecPre1_Y\"))\n",
    "\n",
    "df = df.withColumn(\"Vertex_pRecPi_T\", hypot(col(\"Vertex_pRecPi_X\"), col(\"Vertex_pRecPi_Y\")).cast(\"double\"))\n",
    "df = df.withColumn(\"Vertex_pRecPrePi_T\", hypot(col(\"Vertex_pRecPrePi_X\"), col(\"Vertex_pRecPrePi_Y\")).cast(\"double\"))\n",
    "\n",
    "df = df.withColumn(\"Vertex_pRecPi_mod\", hypot(col(\"Vertex_pRecPi_T\"), col(\"Vertex_pRecPi_Z\")).cast(\"double\"))\n",
    "df = df.withColumn(\"Vertex_pRecPrePi_mod\", hypot(col(\"Vertex_pRecPrePi_T\"), col(\"Vertex_pRecPrePi_Z\")).cast(\"double\"))\n",
    "df = df.withColumn(\"Vertex_pRecPi_sTh\", col(\"Vertex_pRecPi_T\") / col(\"Vertex_pRecPi_mod\"))\n",
    "df = df.withColumn(\"Vertex_pRecPrePi_sTh\", col(\"Vertex_pRecPrePi_T\") / col(\"Vertex_pRecPrePi_mod\"))\n",
    "\n",
    "df = df.withColumn(\"Vertex_pBestPi_Z\", col(\"Vertex_pBest0_Z\") + col(\"Vertex_pBest1_Z\"))\n",
    "df = df.withColumn(\"Vertex_pBestPi_X\", col(\"Vertex_pBest0_X\") + col(\"Vertex_pBest1_X\"))\n",
    "df = df.withColumn(\"Vertex_pBestPi_Y\", col(\"Vertex_pBest0_Y\") + col(\"Vertex_pBest1_Y\"))\n",
    "\n",
    "df = df.withColumn(\"Vertex_pBestPi_T\", hypot(col(\"Vertex_pBestPi_X\"), col(\"Vertex_pBestPi_Y\")).cast(\"double\"))\n",
    "\n",
    "df = df.withColumn(\"Vertex_pBestPi_mod\", hypot(col(\"Vertex_pBestPi_T\"), col(\"Vertex_pBestPi_Z\")).cast(\"double\"))\n",
    "df = df.withColumn(\"Vertex_pBestPi_sTh\", col(\"Vertex_pBestPi_T\") / col(\"Vertex_pBestPi_mod\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f925195",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# boolean analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d681b40",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "shift_fv = 150  # FV frame shift to match the data reference system\n",
    "\n",
    "bool_sig_udf = udf(lambda s_class : s_class==\"k-pinunu\")\n",
    "bool_bkg_udf = udf(lambda s_class : s_class!=\"k-pinunu\")\n",
    "bool_2mec_udf = udf(lambda s_class : s_class!=\"\")\n",
    "bool_fv_udf = udf(lambda z_vtx : (z_vtx > (280-shift_fv)) & (z_vtx < (350-shift_fv)))\n",
    "bool_rmin_udf = udf(lambda r_min : r_min > 35e-2)\n",
    "bool_emin_udf = udf(lambda e_min, r_e_min : e_min > (2/r_e_min))\n",
    "bool_pt_udf = udf(lambda p_t : p_t > 0.140)\n",
    "bool_psv_udf = udf(lambda n_conv, z_vtx_pre, p_t_pre : (n_conv > 0) & (z_vtx_pre < (350-shift_fv)) & (p_t_pre > 0.140))\n",
    "bool_even_udf = udf(lambda i_pair : i_pair==1)\n",
    "bool_odd_udf = udf(lambda i_pair : i_pair==0)\n",
    "bool_nofused_udf = udf(lambda n_hit_0, n_hit_1 : (n_hit_0==1) & (n_hit_1==1))\n",
    "bool_fused_udf = udf(lambda n_hit_0, n_hit_1 : (n_hit_0!=1) | (n_hit_1!=1))\n",
    "\n",
    "df = df.withColumn(\"bool_sig\", bool_sig_udf(col(\"class_lab\")).cast(\"boolean\"))\n",
    "df = df.withColumn(\"bool_bkg\", bool_bkg_udf(col(\"class_lab\")).cast(\"boolean\"))\n",
    "df = df.withColumn(\"bool_2mec\", bool_2mec_udf(col(\"class_lab\")).cast(\"boolean\"))\n",
    "df = df.withColumn(\"bool_fv\", bool_fv_udf(col(\"Vertex_xRec_Z\")).cast(\"boolean\"))\n",
    "df = df.withColumn(\"bool_rmin\", bool_rmin_udf(col(\"Clusters_xRec_TMin\")).cast(\"boolean\"))\n",
    "df = df.withColumn(\"bool_emin\", bool_emin_udf(col(\"Clusters_EMin\"), col(\"Clusters_xRec_TEMin\")).cast(\"boolean\"))\n",
    "df = df.withColumn(\"bool_pt\", bool_pt_udf(col(\"Vertex_pRecPi_T\")).cast(\"boolean\"))\n",
    "df = df.withColumn(\"bool_psv\", bool_psv_udf(col(\"Vertex_nConverted\"), col(\"Vertex_xRecPre_Z\"), col(\"Vertex_pRecPrePi_T\")).cast(\"boolean\"))\n",
    "df = df.withColumn(\"bool_even\", bool_even_udf(col(\"iPair\")).cast(\"boolean\"))\n",
    "df = df.withColumn(\"bool_odd\", bool_odd_udf(col(\"iPair\")).cast(\"boolean\"))\n",
    "df = df.withColumn(\"bool_nofused\", bool_nofused_udf(col(\"Cluster0_nHits\"), col(\"Cluster1_nHits\")).cast(\"boolean\"))\n",
    "df = df.withColumn(\"bool_fused\", bool_fused_udf(col(\"Cluster0_nHits\"), col(\"Cluster1_nHits\")).cast(\"boolean\"))\n",
    "\n",
    "# booleans: with 2 photons in MEC (i.e. the total dataset for each class)\n",
    "df = df.withColumn(\"bool_sig_2mec\", col(\"bool_sig\") & col(\"bool_2mec\"))\n",
    "df = df.withColumn(\"bool_bkg_2mec\", col(\"bool_bkg\") & col(\"bool_2mec\"))\n",
    "df = df.withColumn(\"bool_bkgEv_2mec\", col(\"bool_nofused\") & col(\"bool_even\") & col(\"bool_bkg\") & col(\"bool_2mec\"))\n",
    "df = df.withColumn(\"bool_bkgOd_2mec\", col(\"bool_nofused\") & ~col(\"bool_even\") & col(\"bool_bkg\") & col(\"bool_2mec\"))\n",
    "df = df.withColumn(\"bool_bkgFs_2mec\", ~col(\"bool_nofused\") & col(\"bool_bkg\") & col(\"bool_2mec\"))\n",
    "\n",
    "# booleans: reconstructed in FV with MEC only\n",
    "df = df.withColumn(\"bool_sig_2mec_fv\", col(\"bool_sig_2mec\") & col(\"bool_fv\"))\n",
    "df = df.withColumn(\"bool_bkg_2mec_fv\", col(\"bool_bkg_2mec\") & col(\"bool_fv\"))\n",
    "df = df.withColumn(\"bool_bkgEv_2mec_fv\", col(\"bool_bkgEv_2mec\") & col(\"bool_fv\"))\n",
    "df = df.withColumn(\"bool_bkgOd_2mec_fv\", col(\"bool_bkgOd_2mec\") & col(\"bool_fv\"))\n",
    "df = df.withColumn(\"bool_bkgFs_2mec_fv\", col(\"bool_bkgFs_2mec\") & col(\"bool_fv\"))\n",
    "\n",
    "# booleans: cut on minimum-radius cluster (>35 cm)\n",
    "df = df.withColumn(\"bool_sig_2mec_fv_rmin\", col(\"bool_sig_2mec_fv\") & col(\"bool_rmin\"))\n",
    "df = df.withColumn(\"bool_bkg_2mec_fv_rmin\", col(\"bool_bkg_2mec_fv\") & col(\"bool_rmin\"))\n",
    "df = df.withColumn(\"bool_bkgEv_2mec_fv_rmin\", col(\"bool_bkgEv_2mec_fv\") & col(\"bool_rmin\"))\n",
    "df = df.withColumn(\"bool_bkgOd_2mec_fv_rmin\", col(\"bool_bkgOd_2mec_fv\") & col(\"bool_rmin\"))\n",
    "df = df.withColumn(\"bool_bkgFs_2mec_fv_rmin\", col(\"bool_bkgFs_2mec_fv\") & col(\"bool_rmin\"))\n",
    "\n",
    "# booleans: cut minimum-energy cluster (>2 GeV divided by corresponding cluster radius)\n",
    "df = df.withColumn(\"bool_sig_2mec_fv_rmin_emin\", col(\"bool_sig_2mec_fv_rmin\") & col(\"bool_emin\"))\n",
    "df = df.withColumn(\"bool_bkg_2mec_fv_rmin_emin\", col(\"bool_bkg_2mec_fv_rmin\") & col(\"bool_emin\"))\n",
    "df = df.withColumn(\"bool_bkgEv_2mec_fv_rmin_emin\", col(\"bool_bkgEv_2mec_fv_rmin\") & col(\"bool_emin\"))\n",
    "df = df.withColumn(\"bool_bkgOd_2mec_fv_rmin_emin\", col(\"bool_bkgOd_2mec_fv_rmin\") & col(\"bool_emin\"))\n",
    "df = df.withColumn(\"bool_bkgFs_2mec_fv_rmin_emin\", col(\"bool_bkgFs_2mec_fv_rmin\") & col(\"bool_emin\"))\n",
    "\n",
    "# booleans: cut on pion transverse momentum (>0.140 GeV) computed with MEC only\n",
    "df = df.withColumn(\"bool_sig_2mec_fv_rmin_emin_pt\", col(\"bool_sig_2mec_fv_rmin_emin\") & col(\"bool_pt\"))\n",
    "df = df.withColumn(\"bool_bkg_2mec_fv_rmin_emin_pt\", col(\"bool_bkg_2mec_fv_rmin_emin\") & col(\"bool_pt\"))\n",
    "df = df.withColumn(\"bool_bkgEv_2mec_fv_rmin_emin_pt\", col(\"bool_bkgEv_2mec_fv_rmin_emin\") & col(\"bool_pt\"))\n",
    "df = df.withColumn(\"bool_bkgOd_2mec_fv_rmin_emin_pt\", col(\"bool_bkgOd_2mec_fv_rmin_emin\") & col(\"bool_pt\"))\n",
    "df = df.withColumn(\"bool_bkgFs_2mec_fv_rmin_emin_pt\", col(\"bool_bkgFs_2mec_fv_rmin_emin\") & col(\"bool_pt\"))\n",
    "\n",
    "# booleans: adding the PSV data\n",
    "df = df.withColumn(\"bool_sig_2mec_fv_rmin_emin_pt_psv\", col(\"bool_sig_2mec_fv_rmin_emin_pt\") & col(\"bool_psv\"))\n",
    "df = df.withColumn(\"bool_bkg_2mec_fv_rmin_emin_pt_psv\", col(\"bool_bkg_2mec_fv_rmin_emin_pt\") & col(\"bool_psv\"))\n",
    "df = df.withColumn(\"bool_bkgEv_2mec_fv_rmin_emin_pt_psv\", col(\"bool_bkgEv_2mec_fv_rmin_emin_pt\") & col(\"bool_psv\"))\n",
    "df = df.withColumn(\"bool_bkgOd_2mec_fv_rmin_emin_pt_psv\", col(\"bool_bkgOd_2mec_fv_rmin_emin_pt\") & col(\"bool_psv\"))\n",
    "df = df.withColumn(\"bool_bkgFs_2mec_fv_rmin_emin_pt_psv\", col(\"bool_bkgFs_2mec_fv_rmin_emin_pt\") & col(\"bool_psv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276c9d2b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# now count events...\n",
    "\n",
    "get_n = lambda s : df.filter(df[s]).select(sum(df[\"W\"])).collect()[0][0]\n",
    "\n",
    "# with 2 photons in MEC (i.e. the total dataset for each class)\n",
    "cuts = \"2mec\"\n",
    "print(\"counting events in subset %s...\" % cuts)\n",
    "#n_sig_2mec = get_n(\"bool_sig_%s\" % cuts)\n",
    "n_bkg_2mec = get_n(\"bool_bkg_%s\" % cuts)\n",
    "#n_bkgEv_2mec = get_n(\"bool_bkgEv_%s\" % cuts)\n",
    "#n_bkgOd_2mec = get_n(\"bool_bkgOd_%s\" % cuts)\n",
    "#n_bkgFs_2mec = get_n(\"bool_bkgFs_%s\" % cuts)\n",
    "\n",
    "# reconstructed in FV with MEC only\n",
    "cuts = \"2mec_fv\"\n",
    "print(\"counting events in subset %s...\" % cuts)\n",
    "#n_sig_2mec_fv = get_n(\"bool_sig_%s\" % cuts)\n",
    "n_bkg_2mec_fv = get_n(\"bool_bkg_%s\" % cuts)\n",
    "#n_bkgEv_2mec_fv = get_n(\"bool_bkgEv_%s\" % cuts)\n",
    "#n_bkgOd_2mec_fv = get_n(\"bool_bkgOd_%s\" % cuts)\n",
    "#n_bkgFs_2mec_fv = get_n(\"bool_bkgFs_%s\" % cuts)\n",
    "\n",
    "# cut on minimum-radius cluster (>35 cm)\n",
    "cuts = \"2mec_fv_rmin\"\n",
    "print(\"counting events in subset %s...\" % cuts)\n",
    "#n_sig_2mec_fv_rmin = get_n(\"bool_sig_%s\" % cuts)\n",
    "n_bkg_2mec_fv_rmin = get_n(\"bool_bkg_%s\" % cuts)\n",
    "#n_bkgEv_2mec_fv_rmin = get_n(\"bool_bkgEv_%s\" % cuts)\n",
    "#n_bkgOd_2mec_fv_rmin = get_n(\"bool_bkgOd_%s\" % cuts)\n",
    "#n_bkgFs_2mec_fv_rmin = get_n(\"bool_bkgFs_%s\" % cuts)\n",
    "\n",
    "# cut minimum-energy cluster (>2 GeV divided by corresponding cluster radius)\n",
    "cuts = \"2mec_fv_rmin_emin\"\n",
    "print(\"counting events in subset %s...\" % cuts)\n",
    "#n_sig_2mec_fv_rmin_emin = get_n(\"bool_sig_%s\" % cuts)\n",
    "n_bkg_2mec_fv_rmin_emin = get_n(\"bool_bkg_%s\" % cuts)\n",
    "#n_bkgEv_2mec_fv_rmin_emin = get_n(\"bool_bkgEv_%s\" % cuts)\n",
    "#n_bkgOd_2mec_fv_rmin_emin = get_n(\"bool_bkgOd_%s\" % cuts)\n",
    "#n_bkgFs_2mec_fv_rmin_emin = get_n(\"bool_bkgFs_%s\" % cuts)\n",
    "\n",
    "# cut on pion transverse momentum (>0.140 GeV) computed with MEC only\n",
    "cuts = \"2mec_fv_rmin_emin_pt\"\n",
    "print(\"counting events in subset %s...\" % cuts)\n",
    "#n_sig_2mec_fv_rmin_emin_pt = get_n(\"bool_sig_%s\" % cuts)\n",
    "n_bkg_2mec_fv_rmin_emin_pt = get_n(\"bool_bkg_%s\" % cuts)\n",
    "#n_bkgEv_2mec_fv_rmin_emin_pt = get_n(\"bool_bkgEv_%s\" % cuts)\n",
    "#n_bkgOd_2mec_fv_rmin_emin_pt = get_n(\"bool_bkgOd_%s\" % cuts)\n",
    "#n_bkgFs_2mec_fv_rmin_emin_pt = get_n(\"bool_bkgFs_%s\" % cuts)\n",
    "\n",
    "# adding the PSV data\n",
    "cuts = \"2mec_fv_rmin_emin_pt_psv\"\n",
    "print(\"counting events in subset %s...\" % cuts)\n",
    "#n_sig_2mec_fv_rmin_emin_pt_psv = get_n(\"bool_sig_%s\" % cuts)\n",
    "n_bkg_2mec_fv_rmin_emin_pt_psv = get_n(\"bool_bkg_%s\" % cuts)\n",
    "#n_bkgEv_2mec_fv_rmin_emin_pt_psv = get_n(\"bool_bkgEv_%s\" % cuts)\n",
    "#n_bkgOd_2mec_fv_rmin_emin_pt_psv = get_n(\"bool_bkgOd_%s\" % cuts)\n",
    "#n_bkgFs_2mec_fv_rmin_emin_pt_psv = get_n(\"bool_bkgFs_%s\" % cuts)\n",
    "\n",
    "print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a356c6a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# total events (with 2 photons in MEC) in the LoI:\n",
    "normSig = 302\n",
    "normBkg = 2.29e5  #9.45e7\n",
    "#normSig = 37800/70e6 * n_sig_2mec  \n",
    "#normBkg = 1.089e12/(500*500e6 + 7e9) * n_bkg_2mec  \n",
    "\n",
    "#print(\"counts for signal:\")\n",
    "#print(normSig*n_sig_2mec/n_sig_2mec)\n",
    "#print(normSig*n_sig_2mec_fv/n_sig_2mec)\n",
    "#print(normSig*n_sig_2mec_fv_rmin/n_sig_2mec)\n",
    "#print(normSig*n_sig_2mec_fv_rmin_emin/n_sig_2mec)\n",
    "#print(normSig*n_sig_2mec_fv_rmin_emin_pt/n_sig_2mec)\n",
    "#print(normSig*n_sig_2mec_fv_rmin_emin_pt_psv/n_sig_2mec)\n",
    "\n",
    "#print(\"---\\ncounts for background (total):\")\n",
    "print(\"counts for background (total):\")\n",
    "print(normBkg*n_bkg_2mec/n_bkg_2mec)\n",
    "print(normBkg*n_bkg_2mec_fv/n_bkg_2mec)\n",
    "print(normBkg*n_bkg_2mec_fv_rmin_emin/n_bkg_2mec)\n",
    "print(normBkg*n_bkg_2mec_fv_rmin_emin_pt/n_bkg_2mec)\n",
    "print(normBkg*n_bkg_2mec_fv_rmin_emin_pt_psv/n_bkg_2mec)\n",
    "\n",
    "#print(\"---\\ncounts for background (even, not fused):\")\n",
    "#print(normBkg*n_bkgEv_2mec/n_bkg_2mec)\n",
    "#print(normBkg*n_bkgEv_2mec_fv/n_bkg_2mec)\n",
    "#print(normBkg*n_bkgEv_2mec_fv_rmin_emin/n_bkg_2mec)\n",
    "#print(normBkg*n_bkgEv_2mec_fv_rmin_emin_pt/n_bkg_2mec)\n",
    "#print(normBkg*n_bkgEv_2mec_fv_rmin_emin_pt_psv/n_bkg_2mec)\n",
    "#\n",
    "#print(\"---\\ncounts for background (odd, not fused):\")\n",
    "#print(normBkg*n_bkgOd_2mec/n_bkg_2mec)\n",
    "#print(normBkg*n_bkgOd_2mec_fv/n_bkg_2mec)\n",
    "#print(normBkg*n_bkgOd_2mec_fv_rmin_emin/n_bkg_2mec)\n",
    "#print(normBkg*n_bkgOd_2mec_fv_rmin_emin_pt/n_bkg_2mec)\n",
    "#print(normBkg*n_bkgOd_2mec_fv_rmin_emin_pt_psv/n_bkg_2mec)\n",
    "#\n",
    "#print(\"---\\ncounts for background (fused):\")\n",
    "#print(normBkg*n_bkgFs_2mec/n_bkg_2mec)\n",
    "#print(normBkg*n_bkgFs_2mec_fv/n_bkg_2mec)\n",
    "#print(normBkg*n_bkgFs_2mec_fv_rmin_emin/n_bkg_2mec)\n",
    "#print(normBkg*n_bkgFs_2mec_fv_rmin_emin_pt/n_bkg_2mec)\n",
    "#print(normBkg*n_bkgFs_2mec_fv_rmin_emin_pt_psv/n_bkg_2mec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32151e8f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# plots - define function to generate the 2-dimensional histograms\n",
    "bPlots = True\n",
    "\n",
    "def custom_hist2d(df, x, y, bins):\n",
    "    hist2d = []\n",
    "    for ix in range(len(bins[0])-1):\n",
    "        bool_dk_udf = udf(lambda k : bool((k>=bins[0][ix]) & (k<bins[0][ix+1])))\n",
    "        df_temp = df.withColumn(\"bool_dx\", bool_dk_udf(col(x)).cast(\"boolean\"))\n",
    "        df_temp = df_temp.filter(\"bool_dx\")\n",
    "        #hist2d_0 = df_temp.select(x, y).select(y).rdd.flatMap(lambda q: q).histogram(bins[1])\n",
    "        #hist2d.append(hist2d_0[1])\n",
    "        hist2d_0 = computeWeightedHistogram(df_temp, y, \"W\", np.min(bins[1]), np.max(bins[1]), len(bins[1])-1).toPandas()\n",
    "        hist2d.append(hist2d_0[\"weighted_sum\"])\n",
    "    return [bins[0], bins[1], hist2d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea3e198",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# plots - generate the 2-dimensional histograms --> in hists\n",
    "if bPlots:\n",
    "\n",
    "    range_plot = ((150-shift_fv, 400-shift_fv), (0, 0.4)) \n",
    "    nbins = (100, 50)\n",
    "\n",
    "    hists = [[], []]\n",
    "    for i_class in [0]:\n",
    "\n",
    "        df_R0 = df.filter(\"bool_2mec\").filter(\"bool_rmin\").filter(\"bool_emin\")\n",
    "        #if i_class==0:\n",
    "        #    df_L = df.filter(\"bool_sig\")\n",
    "        #    df_R = df_R0.filter(\"bool_sig\").filter(\"bool_psv\")\n",
    "        if i_class==0:\n",
    "            df_L = df.filter(\"bool_bkg\")\n",
    "            df_R = df_R0.filter(\"bool_bkg\").filter(\"bool_psv\")\n",
    "        if i_class==1:\n",
    "            df_L = df.filter(\"bool_bkg\").filter(\"bool_nofused\").filter(\"bool_even\")\n",
    "            df_R = df_R0.filter(\"bool_bkg\").filter(\"bool_nofused\").filter(\"bool_even\")\n",
    "        if i_class==2:\n",
    "            df_L = df.filter(\"bool_bkg\").filter(\"bool_nofused\").filter(\"bool_odd\")\n",
    "            df_R = df_R0.filter(\"bool_bkg\").filter(\"bool_nofused\").filter(\"bool_odd\")\n",
    "        if i_class==3:\n",
    "            df_L = df.filter(\"bool_bkg\").filter(\"bool_fused\")\n",
    "            df_R = df_R0.filter(\"bool_bkg\").filter(\"bool_fused\")\n",
    "\n",
    "        hist = custom_hist2d(\n",
    "            df_L, \"Vertex_xRec_Z\", \"Vertex_pRecPi_T\",\n",
    "            (tuple(np.linspace(150-shift_fv, 400-shift_fv, nbins[0]+1)), tuple(np.linspace(0, 0.4, nbins[1]+1)))\n",
    "        )\n",
    "        hists[0].append(hist)\n",
    "\n",
    "        hist = custom_hist2d(\n",
    "            df_R, \"Vertex_xRec_Z\", \"Vertex_pRecPi_T\",\n",
    "            (tuple(np.linspace(150-shift_fv, 400-shift_fv, nbins[0]+1)), tuple(np.linspace(0, 0.4, nbins[1]+1)))\n",
    "        )\n",
    "        hists[1].append(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d599fc3f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# plots - plot the histograms\n",
    "if bPlots:\n",
    "\n",
    "    bPreBool_save = True  # save plots?\n",
    "\n",
    "    bLog = False\n",
    "    cmap_name = \"jet\"\n",
    "\n",
    "    #cmap = LinearSegmentedColormap.from_list(\n",
    "    #    \"%s_white\" % cmap_name, \n",
    "    #    list(np.concatenate((np.array([[0, 0, 0, 0]]), plt.get_cmap(cmap_name)(np.arange(256))))),\n",
    "    #)\n",
    "    cmap = plt.get_cmap(cmap_name).copy()\n",
    "    cmap.set_bad('white')\n",
    "\n",
    "    for i_class in [0]:\n",
    "        fig, ax = plt.subplots(num=i_class, nrows=1, ncols=2, figsize=(12, 4))\n",
    "        hist = hists[0][i_class]\n",
    "        for ia, a in enumerate(hist[2]):\n",
    "            for ib, b in enumerate(a):\n",
    "                if (b<=0): hist[2][ia][ib] = np.nan\n",
    "        \n",
    "        ax[0].imshow(\n",
    "            np.flip(np.array(hist[2]).T, axis=0), \n",
    "            extent=(hist[0][0], hist[0][-1], hist[1][0], hist[1][-1]), \n",
    "            aspect=\"auto\", cmap=cmap, norm=LogNorm() if bLog else None, interpolation=\"none\"\n",
    "        )\n",
    "\n",
    "        hist = hists[1][i_class]\n",
    "        for ia, a in enumerate(hist[2]):\n",
    "            for ib, b in enumerate(a):\n",
    "                if (b<=0): hist[2][ia][ib] = np.nan\n",
    "        \n",
    "        ax[1].imshow(\n",
    "            np.flip(np.array(hist[2]).T, axis=0), \n",
    "            extent=(hist[0][0], hist[0][-1], hist[1][0], hist[1][-1]), \n",
    "            aspect=\"auto\", cmap=cmap, norm=LogNorm() if bLog else None, interpolation=\"none\"\n",
    "        )\n",
    "\n",
    "        box = ((280-shift_fv, 1), (280-shift_fv, 0.14), (350-shift_fv, 0.14), (350-shift_fv, 1))\n",
    "        x_box, y_box = zip(*box)\n",
    "        ax[0].plot(x_box, y_box, color=\"0.7\", lw=3)\n",
    "        ax[1].plot(x_box, y_box, color=\"0.7\", lw=3)\n",
    "\n",
    "        titles = [\"signal\", \"background, even, not fused\", \"background, odd, not fused\", \"background, fused\"]\n",
    "        #fig.suptitle(titles[i_class])\n",
    "        fig.suptitle(\"lambda background, total\")\n",
    "        fig.supxlabel(\"Vertex_xRec_Z [m]\")\n",
    "        fig.supylabel(\"Vertex_pRecPi_T [GeV]\")\n",
    "        for i in (0, 1): ax[i].set_ylim((0, 0.4))\n",
    "        fig.tight_layout()\n",
    "        if bPreBool_save:\n",
    "            #fig.savefig(\"./output_misc/%s_SPARK.png\" % titles[i_class].replace(\",\", \"_\").replace(\" \", \"\"))\n",
    "            fig.savefig(\"./output_misc/lambda_SPARK.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e177c46e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# stop Spark session\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "sparkconnect": {
   "bundled_options": [
    "EOSFilesystem"
   ],
   "list_of_options": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
